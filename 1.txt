import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
from sklearn import metrics
from sklearn import svm
import matplotlib.pyplot as plt
from mlxtend.plotting import plot_decision_regions
import graphviz

data1 = pd.read_csv('Data1.csv')
feature_names1 = data1.loc[:,'X':'Y']
target_names1 = data1.loc[:,'C']

Data_X = data1.values[:,0:2]
Data_Y = data1.values[:,2]

from sklearn.model_selection import KFold
#import pickle
#list1 = []
tree1 = []
total_accuracy = 0
total_precision = 0
total_recall = 0
kf = KFold(n_splits = 5, random_state = None, shuffle = True)
for train_index, test_index in kf.split(Data_X):
    X_train, X_test = Data_X[train_index], Data_X[test_index]
    Y_train, Y_test = Data_Y[train_index], Data_Y[test_index]
    #print(Y_train)
    #clf = svm.SVC(kernel='linear', C=10, random_state=0)
    clf = DecisionTreeClassifier(criterion = "entropy", min_samples_leaf = 30, max_leaf_nodes = 3)
    clf = clf.fit(X_train, Y_train)
    tree1.append(clf)
    pred = clf.predict(X_test)
    #list1.append(pickle.load(clf))
    #metrics.accuracy_scores()
    Accuracy = metrics.accuracy_score(Y_test,pred)*100
    Precision = metrics.precision_score(Y_test, pred, average = None)*100
    Recall = metrics.recall_score(Y_test, pred, average = None)*100
    print ("Accuracy:  ", metrics.accuracy_score(Y_test,pred)*100)
    print("Precision:", metrics.precision_score(Y_test, pred, average = None)*100)
    print("Recall: ", metrics.recall_score(Y_test, pred, average = None)*100)
    #if Accuracy == 100 and Precision == 100 and Recall == 100:
    total_accuracy += Accuracy
    total_precision += Precision
    total_recall += Recall
    Y_train = Y_train.astype(int)
    plot_decision_regions(X_train,Y_train, clf, legend=2)
    plt.show()
print("Average Acccuarcy: ", total_accuracy/5)
print("Average Precision: ", total_precision/5)
print("Average Recall: ", total_recall/5)
#print(list1)

	